{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55afc52e-1e6f-4992-a237-d6c65851c41a",
   "metadata": {},
   "source": [
    "Este es un ejemplo extraído del tutorial \"Convolutional Neural \n",
    "Networks in Python with Keras\" de la página \"Datacamp\" por Aditya Sharma. \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
    "\n",
    "<hr>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-natural",
   "metadata": {},
   "source": [
    "<h1>REDES NEURONALES CONVOLUCIONALES CON KERAS</h1>\n",
    "El Dataset Fashion-MNIST se encuentra disponible en la librería \n",
    "datasets de Keras y contiene imágenes de los artículos de Zalando \n",
    "(tienda de moda en línea alemana). Las imágenes son \n",
    "escala de grises de 28x28 y corresponden a 70.000 productos \n",
    "de moda de 10 categorías diferentes (7.000 imágenes por categoría). \n",
    "El conjunto de entrenamiento tiene 60.000 imágenes y el conjunto \n",
    "de prueba tiene 10.000 imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-clone",
   "metadata": {},
   "source": [
    "Las imágenes de entrenamiento y prueba, junto con sus etiquetas \n",
    "correspondientes, se almacenan en las variables <i>train_images, \n",
    "train_labels, test_images</i> y <i>test_labels</i> respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set shape: ({train_images.shape}, {train_labels.shape})\")\n",
    "\n",
    "print(f\"Test set shape: ({test_images.shape},{test_labels.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "plt.subplot(121)\n",
    "curr_img = train_images[0]\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "plt.subplot(122)\n",
    "curr_img = test_images[0]\n",
    "curr_lbl = test_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-musical",
   "metadata": {},
   "source": [
    "Es necesario realizar un preprocesamiento de los datos para poder \n",
    "utilizarlos en el modelo:\n",
    "<ol>\n",
    "    <li>Convertir cada imagen de 28x28 en una matriz de 28x28x1.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 28,28, 1)\n",
    "test_images = test_images.reshape(-1, 28,28, 1)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-division",
   "metadata": {},
   "source": [
    "<ol start=\"2\">\n",
    "    <li>Convertir los datos de tipo int8 a float32.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-effect",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "    <li>Re-escalar los valores de los pixeles del rango 0-255 a 0-1.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-information",
   "metadata": {},
   "source": [
    "<ol start=\"4\">\n",
    "    <li>Convertir las etiquetas de clase en un vector de codificación \n",
    "        <i>one-hot</i>: Esto es necesario porque \n",
    "        los algoritmos de aprendizaje automático no pueden \n",
    "        trabajar directamente con datos categóricos. En la codificación \n",
    "        one-hot, se convierten los datos categóricos en un vector \n",
    "        de números. Se genera una columna\n",
    "        para cada categoría o clase. Por lo que, cada vector de \n",
    "        codificación consiste de todos ceros excepto por un 1 que \n",
    "        indica a la clase que corresponde.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels_oh = to_categorical(train_labels)\n",
    "test_labels_oh = to_categorical(test_labels)\n",
    "\n",
    "print('Original label:', train_labels[0])\n",
    "print('After conversion to one-hot:', train_labels_oh[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-nerve",
   "metadata": {},
   "source": [
    "<ol start=\"5\">\n",
    "    <li>Dividir el set de datos de entrenamiento en datos de entrenamiento \n",
    "    y validación.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_label,valid_label = train_test_split(train_images, train_labels_oh, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-keyboard",
   "metadata": {},
   "source": [
    "La red neuronal a aplicar consiste de:\n",
    "<ul>\n",
    "    <li>Una primera capa con 32 filtros 3x3.</li>\n",
    "    <li>Una segunda capa con 64 filtros 3x3.</li>\n",
    "    <li>Una tercera capa con 128 filtros 3x3.</li>\n",
    "    <li>3 capas de tipo max-pooling de tamaño 2x2 luego \n",
    "        de cada capa convolucional.</li>\n",
    "    <li>Una capa densa de 128 neuronas.</li>\n",
    "    <li>Una capa de salida con 10 neuronas.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-windows",
   "metadata": {},
   "source": [
    "<b>Batch size</b> es el número de ejemplos de entrenamiento que son \n",
    "utilizados en cada iteración.\n",
    "\n",
    "<b>Epoch</b> es un término para indicar el número de veces que todo\n",
    "el set de datos de entrenamiento atraviesa el algoritmo. Mientras \n",
    "que <b>iteración</b> hace referencia a cuando un batch de datos atraviesa el \n",
    "algoritmo. En el caso de que el tamaño de batch sea igual al tamaño del \n",
    "set de datos de entrenamiento, el número de epochs y de iteraciones \n",
    "sería el mismo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1),padding='same'))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                 \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='relu'))                \n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train = fashion_model.fit(train_X, train_label, batch_size = batch_size, epochs = epochs, verbose = 1,validation_data = (valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = fashion_model.evaluate(test_images, test_labels_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = fashion_train.history['accuracy']\n",
    "val_accuracy = fashion_train.history['val_accuracy']\n",
    "loss = fashion_train.history['loss']\n",
    "val_loss = fashion_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-extra",
   "metadata": {},
   "source": [
    "<h2>APLICANDO DROPOUT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding='same',input_shape=(28,28,1)))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                 \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.4))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='relu'))        \n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = fashion_model.evaluate(test_images, test_labels_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = fashion_train_dropout.history['accuracy']\n",
    "val_accuracy = fashion_train_dropout.history['val_accuracy']\n",
    "loss = fashion_train_dropout.history['loss']\n",
    "val_loss = fashion_train_dropout.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = fashion_model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_classes==test_labels)[0]\n",
    "print (f\"Found {len(correct)} correct labels\") \n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_images[correct].reshape(28,28), cmap='gray')\n",
    "    plt.title(f\"Predicted {predicted_classes[correct]}, Class {test_labels[correct]}\")\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes != test_labels)[0]\n",
    "print (f\"Found {len(incorrect)} incorrect labels\")\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_images[incorrect].reshape(28,28), cmap='gray')\n",
    "    plt.title(f\"Predicted {predicted_classes[incorrect]}, Class {test_labels[incorrect]}\")\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "print(classification_report(test_labels, predicted_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
